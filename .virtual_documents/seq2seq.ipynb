get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")
from main import Config, load_data
from seqmodels import *


## Space to explore
# two types of encoders
# batch size
# lr
# size of input seq and output seq
# 


## Output Summarization for error analytics
## given a sequence -> reduce to output
    # contains add to cart 
    # contains checkout 
    # loops between pages 
    # contains successful checkout 
    # faces issues after doing ... 
    # 


# set config and read graph data in gretel format (will be re-written later)
DOMAIN = 'pollini'
config, DEVICE = load_config(DOMAIN)
graph, trajectories, pairwise_node_features, _ = load_data(config)


hidden_size = 512 #HP
dp = 0.1 #HP
lr = 0.0025 #HP
tf = 0.95 #HP

n_node = graph.n_node
encoder = EncoderRNN(n_node+2, hidden_size).to(DEVICE)
attn_decoder = AttnDecoderRNN(hidden_size, n_node+2, dropout_p=dp).to(DEVICE)
models = trainIters(trajectories[0], encoder, attn_decoder, trajectories[2],
                    n_node+1, n_node, n_epoch=5, learning_rate=lr, tf=tf)


model_params = dict({"hidden_size": hidden_size,"n_node":n_node, "n_in" : n_in, "n_out":n_out, "dp":dp, "lr":lr})
model_file = "./models/"+DOMAIN+"_model.pt"
torch.save({"params": model_params,**models}, model_file)


temp = dict({"encoder" : models["encoder"].state_dict(),
             "decoder" : models["decoder"].state_dict(), 
             "optim_encoder" : models["optim_encoder"].state_dict(), 
             "optim_decoder": models["optim_decoder"].state_dict()})
torch.save({"params":model_params, **temp}, model_file)


training_pairs = tensors_from_paths(trajectories[2], n_in, n_out)
print(evaluateRandomly(encoder, attn_decoder, training_pairs,"fancy_grid", n_out=n_out))


import plotly.express as px
lengths = []

for i in trajectories[2]:
    lengths.append(len(i))
px.histogram(lengths, cumulative=True, histnorm='probability')


class PathPredict(nn.Module):

    def __init__(self, embedding_dim, hidden_dim, vocab_size, n_lstm, bid=False):
        self.hidden_dim = hidden_dim
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_lstm, bidirectional=bid)
        self.h0 = torch.rand(self.num_layers, hidden_dim)  # batch_size?
        self.c0 = torch.rand(self.num_layers, hidden_dim)  # batch_size?
        self.linear = nn.Linear(n_emb*seq_len, n_out)
        self.activation = nn.Sigmoid()

    def foward(self, X):
        emb = self.embedding(X) #[seq_len, bs]
        x = self.lstm(emb) #[seq_len, bs, n_emb]
        y = self.activation(self.linear(x.view(-1, 1)))



n_hid = 4
n_inp = 3
seq_len = 10
num_layers = 2
bid = 1

lstm = nn.LSTM(n_inp, n_hid, num_layers)
x = torch.rand(seq_len, 1, n_inp)
h0 = torch.rand(num_layers, 1, n_hid)
c0 = torch.rand(num_layers, 1, n_hid)
y = lstm(x, (h0,c0))


## lengths distribution 
