get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")
import random
import torch
import torch.nn as nn
import plotly.express as px
import pickle 
from collections import defaultdict
from seqmodels import *
from utils import *


DOMAIN = 'pollini'
models_path = 'models/'+DOMAIN+"_model.pt"


def load_models(models_path):
    models = torch.load(models_path)
    device = "cuda:0"
    params = models['params']
    encoder = EncoderRNN(params["n_node"]+2, params["hidden_size"]).to(device)
    decoder = AttnDecoderRNN(params["hidden_size"], params["n_node"]+2, dropout_p=params["dp"]).to(device)

    encoder.load_state_dict(models['encoder'])
    decoder.load_state_dict(models['decoder'])
    encoder.eval()
    decoder.eval()
    return encoder, decoder


encoder, decoder = load_models(models_path)
error_trajs = pickle.load(open("./data/"+DOMAIN+"/errors.pkl", "rb"))


## Filter trajs and remove 1 and 2 loops
CUTOFF = 10
error_trajs = list(map(lambda x: remove_2loops(remove_self_loops(x)), error_trajs))
error_trajs = list(filter(lambda x: len(x) > CUTOFF, error_trajs))

## get unique error_sigs
err_sigs = set({})
for traj in error_trajs:
    sigs = [node for node in traj if isinstance(node, str)]
    err_sigs.update(set(sigs))
err_sigs = list(err_sigs)

## Get trajs for each error_sig
error_groups=defaultdict(set)
for traj_index, traj in enumerate(error_trajs):
    for node in traj:
        if isinstance(node, str):
            error_groups[node].update({traj_index})

## Filter Errors with too few trajs
errors = []
for err in err_sigs:
    if len(error_groups[err])>CUTOFF:
        errors.append(err)


def error_compress(traj):
    """function return traj with errors removed 
    and for each error the index where it occurs
    """
    errors = set({})
    err_index = defaultdict(list)
    skip = []
    for i, node in enumerate(traj):
        if isinstance(node, str):
            if node not in errors:
                errors.add(node)
            skip.append(i)
            err_index[node].append(i)
    return [traj[i] if i not in skip else -1 for i,_ in enumerate(traj) ], err_index


# traj summarization -> distance to checkout
# error_window (what is happening in the neighborhood of the issue)
# 


error = errors[0]
trajs = error_groups[error]

preds = []
truth = []

for t in trajs:
    traj = error_trajs[t]
    new_traj, errors = error_compress(traj)


encoder.embedding(torch.tensor([3], device="cuda:0"))


## compute node, bi-gram and tri-gram distributions for preds and truths
## compare these distributions to find differences
## distributions of distance to checkout (no-order)

## trajectory divergence (one-by-one)
## destination divergence
## 





lengths = []

for i in error_trajs:
    lengths.append(len(i))


px.histogram(lengths, cumulative=True, histnorm='probability')



